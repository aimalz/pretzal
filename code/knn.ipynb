{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import george\n",
    "import data\n",
    "import util \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#from scipy.stats import beta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "from matplotlib import gridspec\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_vectors():\n",
    "\n",
    "    X_test = np.loadtxt(util.dat_dir()+\"X_test.dat\")\n",
    "    X_train = np.loadtxt(util.dat_dir()+\"X_train.dat\")\n",
    "   \n",
    "    Xerr_test = np.loadtxt(util.dat_dir()+\"Xerr_test.dat\")\n",
    "    Xerr_train = np.loadtxt(util.dat_dir()+\"Xerr_train.dat\")\n",
    "    \n",
    "    Y_test = np.loadtxt(util.dat_dir()+\"Y_test.dat\")\n",
    "    Y_train = np.loadtxt(util.dat_dir()+\"Y_train.dat\")\n",
    "    \n",
    "    return X_test, X_train, Y_test, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler():\n",
    "\n",
    "    X_test, X_train, Y_test, Y_train = data_vectors()\n",
    "    train_X = RS.fit_transform(X_train)\n",
    "    train_Y = Y_train\n",
    "    test_X  = RS.transform(X_test)\n",
    "    test_Y  = Y_test   \n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bins(Y_train,num_bins):\n",
    "    \n",
    "    (nbins_z,nbins_M) = num_bins\n",
    "    \n",
    "    zmin, zmax = min(Y_train[:,0]), max(Y_train[:,0])\n",
    "    Mmin, Mmax = min(Y_train[:,1]), max(Y_train[:,1])\n",
    "   \n",
    "    zgrid = np.linspace(zmin, zmax, nbins_z+1)\n",
    "    Mgrid = np.linspace(Mmin, Mmax, nbins_M+1)\n",
    "\n",
    "    binsize1 = (zmax - zmin)/ nbins_z\n",
    "    binsize2 = (Mmax - Mmin)/ nbins_M\n",
    "    \n",
    "    return (zgrid,Mgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(num_bins, n_neighbors=3):\n",
    "    \n",
    "    \"\"\"\n",
    "    k nearest neighbors classifier for determining p(z)'s.\n",
    "    inputs:\n",
    "    num_bins = number of redshift bins,\n",
    "    num_estimators = number of neighbors,\n",
    "    outputs:\n",
    "    label probabilities + best predictions + feature importance\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" Binning the redshifts\"\"\"\n",
    "   \n",
    "    X_train, Y_train, test_X, test_Y = scaler()\n",
    "    \n",
    "    (nbins_z,nbins_M) = num_bins\n",
    "    (bins_z,bins_M) = make_bins(Y_train,num_bins)\n",
    "    zmin,zmax = min(bins_z),max(bins_z)\n",
    "    Mmin,Mmax = min(bins_M),max(bins_M)\n",
    "    binsize_z = (zmax - zmin)/ nbins_z\n",
    "    binsize_M = (Mmax - Mmin)/ nbins_M\n",
    "    \n",
    "#     #L = np.zeros((len(Y_train)))\n",
    "#     L = np.zeros((len(Y_train), 2))\n",
    "    \n",
    "#     \"\"\" Labeling the bins \"\"\"\n",
    "#     for i in range(nbins):\n",
    "#         for j in range(nbins):\n",
    "#             ij = np.where((Y_train[:,0]>=zmin+i*binsize1)&(Y_train[:,0]<zmin+(i+1)*binsize1)&(Y_train[:,1]>=Mmin+j*binsize2)&(Y_train[:,1]<Mmin+(j+1)*binsize2))\n",
    "#             #print ij, \"ball\"\n",
    "#             L[ij] = [i,j]\n",
    "     \n",
    "    global L\n",
    "    L = np.zeros((len(Y_train)))\n",
    "    global label_list\n",
    "    label_list = [] \n",
    "    \"\"\" Labeling the bins \"\"\"\n",
    "    for i in range(nbins_z):\n",
    "        for j in range(nbins_M):\n",
    "            ij = np.where((Y_train[:,0]>=zmin+i*binsize_z)&(Y_train[:,0]<zmin+(i+1)*binsize_z)&(Y_train[:,1]>=Mmin+j*binsize_M)&(Y_train[:,1]<Mmin+(j+1)*binsize_M))[0]\n",
    "            if (len(ij) != 0 ):\n",
    "                label_list.append([i,j])\n",
    "            L[ij] = i + j * nbins_M\n",
    "    \n",
    "    \"\"\" Splitting the data into training and test sets\"\"\"\n",
    "    \n",
    "    #L = L.astype(int)\n",
    "    \n",
    "    \"\"\" Setting up the KNN classifier\"\"\"\n",
    "\n",
    "    # clf = RandomForestClassifier(n_estimators=num_estimators, max_depth=None, min_samples_split=1, random_state=0)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.n_classes_ = [nbins , nbins]\n",
    "    #clf.classes_ = np.arange(nbins * nbins)    \n",
    "    \"\"\" training \"\"\"\n",
    "    clf.fit(X_train, L)\n",
    "    \"\"\"feature importance \"\"\"\n",
    "    # fi = clf.feature_importances_\n",
    "    \n",
    "    \"\"\"best predictions\"\"\"\n",
    "    Y_pred = clf.predict(test_X)\n",
    "    \"\"\"label probabilities\"\"\"\n",
    "    prob = clf.predict_proba(test_X) \n",
    "    \"\"\"transformation quantities \"\"\"\n",
    "    trans = zmin , binsize_z, Mmin, binsize_M\n",
    "\n",
    "    return prob , Y_pred, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution():\n",
    "\n",
    "    magerrs , mags, masterX, masterY  = data_vectors()\n",
    "\n",
    "    fig = plt.figure(1, figsize=(24,8))\n",
    "    gs = gridspec.GridSpec(1,3)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(masterY[:,0], kde=True, hist=False, label='Redshift')\n",
    "    #ax.set_xlim([0, 2.0])\n",
    "    ax.set_title('Redshift distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('Redshift', fontsize=18)    \n",
    "    ax = plt.subplot(gs[1])\n",
    "    sns.distplot(masterY[:,1], kde=True, hist=False, label=r'$M_{\\star}$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title('stellar mass distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('stellar mass', fontsize=18)    \n",
    "    ax = plt.subplot(gs[2])\n",
    "    sns.distplot(masterY[:,2], kde=True, hist=False, label=r'$SFR$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_title('size', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('R', fontsize=18)    \n",
    "    fig.savefig(\"z.pdf\" , box_inches = \"tight\")\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(mags[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magnitude distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magnitudes', fontsize=18)    \n",
    "    fig.savefig(\"mags.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(magerrs[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magerrs', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magerrs', fontsize=18)    \n",
    "    fig.savefig(\"magerrs.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((10,), (25,), (44886, 117), array([ 477.,  452.,  504., ...,  300.,  580.,  555.]))\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "  \n",
    "RS = RobustScaler()\n",
    "    \n",
    "X_train, Y_train, test_X, test_Y = scaler()\n",
    "\n",
    "nbins = (10,25)\n",
    "nn = 100\n",
    "    \n",
    "prob , bestfit , trans = knn(num_bins = nbins, n_neighbors = nn) \n",
    "zmin , binsize_z, Mmin, binsize_M = trans\n",
    "\n",
    "zrange = zmin + binsize_z * np.arange(nbins[0])\n",
    "mrange = Mmin + binsize_M * np.arange(nbins[1])\n",
    "\n",
    "print(zrange.shape, mrange.shape, prob.shape, bestfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37009,)\n",
      "(117, 2)\n",
      "(44886, 117)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(L))\n",
    "print(np.shape(label_list))\n",
    "print(np.shape(prob))\n",
    "for i in range(prob[:10].shape[0]):\n",
    "    \n",
    "       prob2d = np.zeros(nbins)\n",
    "    \n",
    "       for k in xrange(len(prob[i])):\n",
    "           \n",
    "           prob2d[label_list[k][0] , label_list[k][1]] = prob[i][k]\n",
    "\n",
    "       image = prob2d#[0][i,:][:,None] * prob[1][i,:][None,:] \n",
    "       image = image / np.sum(image)     \n",
    "       #plt.title(str())\n",
    "       plt.imshow(image , interpolation = \"none\", cmap = plt.cm.viridis, origin='lower')#,norm=LogNorm(vmin=-0.0000001, vmax=1))\n",
    "       ytick_locs = range(nbins[0])\n",
    "       ytick_lbls = np.round(zrange,2)\n",
    "       plt.yticks(ytick_locs, ytick_lbls)\n",
    "       plt.ylabel(r'$z$')\n",
    "       xtick_locs = range(nbins[1])\n",
    "       xtick_lbls = np.round(mrange,2)\n",
    "       plt.xticks(xtick_locs, xtick_lbls, rotation='vertical')\n",
    "       plt.xlabel(r'$M_{*}$')\n",
    "       plt.colorbar()\n",
    "       plt.savefig(util.fig_dir()+'knn'+str(i)+\".png\")\n",
    "       plt.close()\n",
    "    \n",
    "       plt.plot(mrange, np.array(np.sum(prob2d,axis=0)), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,1], color='k', linestyle='--') \n",
    "       plt.xlabel(r'$M_{*}$')\n",
    "       plt.savefig(util.fig_dir()+'knn'+str(i)+\"m.png\")\n",
    "       plt.close()\n",
    "       plt.plot(zrange, np.array(np.sum(prob2d,axis=1)), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,0], color='k', linestyle='--') \n",
    "       plt.xlabel(r'$z$')\n",
    "       plt.savefig(util.fig_dir()+'knn'+str(i)+\"z.png\")\n",
    "       plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import george\n",
    "import data\n",
    "import util \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats import beta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "from matplotlib import gridspec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RS = RobustScaler()\n",
    "\n",
    "def data_vectors():\n",
    "\n",
    "    X_test = np.loadtxt(util.dat_dir()+\"X_test.dat\")\n",
    "    X_train = np.loadtxt(util.dat_dir()+\"X_train.dat\")\n",
    "   \n",
    "    Xerr_test = np.loadtxt(util.dat_dir()+\"Xerr_test.dat\")\n",
    "    Xerr_train = np.loadtxt(util.dat_dir()+\"Xerr_train.dat\")\n",
    "    \n",
    "    Y_test = np.loadtxt(util.dat_dir()+\"Y_test.dat\")\n",
    "    Y_train = np.loadtxt(util.dat_dir()+\"Y_train.dat\")\n",
    "    \n",
    "    return X_test, X_train, Y_test, Y_train\n",
    "\n",
    "\n",
    "def scaler():\n",
    "\n",
    "    X_test, X_train, Y_test, Y_train = data_vectors()\n",
    "    train_X = RS.fit_transform(X_train)\n",
    "    train_Y = Y_train\n",
    "    test_X  = RS.transform(X_test)\n",
    "    test_Y  = Y_test   \n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y    \n",
    "\n",
    "\n",
    "def rf(num_bins, num_estimators):\n",
    "    \n",
    "    \"\"\"\n",
    "    random forrest classifier for determining p(z)'s.\n",
    "    inputs:\n",
    "    num_bins = number of redshift bins,\n",
    "    num_estimators = number of estimators in scikit-learn random forrest classifier,\n",
    "    outputs:\n",
    "    label probabilities + best predictions + feature importance\n",
    "    \"\"\"\n",
    "    \"\"\" Binning the redshifts\"\"\"\n",
    "   \n",
    "    X_train, Y_train, test_X, test_Y = scaler()\n",
    "   \n",
    "    nbins = num_bins\n",
    "    zmin, zmax = min(Y_train[:,0]), max(Y_train[:,0])\n",
    "    Mmin, Mmax = min(Y_train[:,1]), max(Y_train[:,1])\n",
    "   \n",
    "    #print Mmin , Mmax, zmin, zmax\n",
    " \n",
    "    zgrid = np.linspace(zmin, zmax, nbins)\n",
    "    Mgrid = np.linspace(Mmin, Mmax, nbins)\n",
    "\n",
    "    binsize1 = (zmax - zmin)/ nbins\n",
    "    binsize2 = (Mmax - Mmin)/ nbins\n",
    "    \n",
    "    #L = np.zeros((len(Y_train)))\n",
    "    L = np.zeros((len(Y_train), 2))\n",
    "    \n",
    "    \n",
    "    \"\"\" Labeling the bins \"\"\"\n",
    "    for i in range(nbins):\n",
    "        for j in range(nbins):\n",
    "            ij = np.where((Y_train[:,0]>=zmin+i*binsize1)&(Y_train[:,0]<zmin+(i+1)*binsize1)&(Y_train[:,1]>=Mmin+j*binsize2)&(Y_train[:,1]<Mmin+(j+1)*binsize2))\n",
    "            #print ij, \"ball\"\n",
    "            L[ij] = [i,j]\n",
    "     \n",
    "    \"\"\" Splitting the data into training and test sets\"\"\"\n",
    "    \n",
    "    #L = L.astype(int)\n",
    "    \n",
    "    \"\"\" Setting up the RF classifier\"\"\"\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=num_estimators, max_depth=None, min_samples_split=1, random_state=0)\n",
    "    clf.n_classes_ = [nbins , nbins]\n",
    "    #clf.classes_ = np.arange(nbins * nbins)    \n",
    "    \"\"\" training \"\"\"\n",
    "    clf.fit(X_train, L)\n",
    "    \"\"\"feature importance \"\"\"\n",
    "    fi = clf.feature_importances_\n",
    "    \n",
    "    \"\"\"best predictions\"\"\"\n",
    "    Y_pred = clf.predict(test_X)\n",
    "    \"\"\"label probabilities\"\"\"\n",
    "    prob = clf.predict_proba(test_X) \n",
    "    \"\"\"transformation quantities \"\"\"\n",
    "    trans = zmin , binsize1, Mmin, binsize2\n",
    "\n",
    "    return prob , Y_pred, trans\n",
    "\n",
    "\n",
    "def plot_distribution():\n",
    "\n",
    "    magerrs , mags, masterX, masterY  = data_vectors()\n",
    "\n",
    "    fig = plt.figure(1, figsize=(24,8))\n",
    "    gs = gridspec.GridSpec(1,3)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(masterY[:,0], kde=True, hist=False, label='Redshift')\n",
    "    #ax.set_xlim([0, 2.0])\n",
    "    ax.set_title('Redshift distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('Redshift', fontsize=18)    \n",
    "    ax = plt.subplot(gs[1])\n",
    "    sns.distplot(masterY[:,1], kde=True, hist=False, label=r'$M_{\\star}$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title('stellar mass distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('stellar mass', fontsize=18)    \n",
    "    ax = plt.subplot(gs[2])\n",
    "    sns.distplot(masterY[:,2], kde=True, hist=False, label=r'$SFR$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_title('size', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('R', fontsize=18)    \n",
    "    fig.savefig(\"z.pdf\" , box_inches = \"tight\")\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(mags[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magnitude distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magnitudes', fontsize=18)    \n",
    "    fig.savefig(\"mags.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(magerrs[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magerrs', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magerrs', fontsize=18)    \n",
    "    fig.savefig(\"magerrs.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from matplotlib.colors import LogNorm\n",
    "    \n",
    "    X_train, Y_train, test_X, test_Y = scaler()\n",
    "    \n",
    "    prob , bestfit , trans = rf(num_bins = 20, num_estimators=500) \n",
    "    zmin , binsize1, Mmin, binsize2 = trans\n",
    "\n",
    "    print prob[0].shape\n",
    "    print prob[1].shape\n",
    "\n",
    "    zrange = zmin + binsize1 * np.arange(10)\n",
    "    mrange = Mmin + binsize2 * np.arange(10)\n",
    "\n",
    "    for i in range(prob[1].shape[0]):\n",
    "\n",
    "       \n",
    "       image = prob[0][i,:][:,None] * prob[1][i,:][None,:] \n",
    "       image = image / np.sum(image)     \n",
    "       plt.imshow(image , interpolation = \"none\", cmap = plt.cm.viridis)#,norm=LogNorm(vmin=-0.0000001, vmax=1))\n",
    "       plt.colorbar()\n",
    "       plt.savefig(util.fig_dir()+str(i)+\".png\")\n",
    "       plt.close()\n",
    "\n",
    "       plt.plot(mrange, np.array(prob[1][i,:]), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,1], color='k', linestyle='--') \n",
    "       plt.savefig(util.fig_dir()+str(i)+\"m.png\")\n",
    "       plt.close()\n",
    "       plt.plot(zrange, np.array(prob[0][i,:]), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,0], color='k', linestyle='--') \n",
    "       plt.savefig(util.fig_dir()+str(i)+\"z.png\")\n",
    "       plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
