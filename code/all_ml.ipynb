{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of machine learning methods for deriving $p(z,\\alpha)$\n",
    "This notebook establishes a framework for using machine learning methods to obtain $p(z,\\alpha)$ information from training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data\n",
    "import util \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "from matplotlib import gridspec\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load testing and training data of the observables 'X' and unobservables 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_vectors():\n",
    "\n",
    "    X_test = np.loadtxt(util.dat_dir()+\"X_test.dat\")\n",
    "    X_train = np.loadtxt(util.dat_dir()+\"X_train.dat\")\n",
    "   \n",
    "    Xerr_test = np.loadtxt(util.dat_dir()+\"Xerr_test.dat\")\n",
    "    Xerr_train = np.loadtxt(util.dat_dir()+\"Xerr_train.dat\")\n",
    "    \n",
    "    Y_test = np.loadtxt(util.dat_dir()+\"Y_test.dat\")\n",
    "    Y_train = np.loadtxt(util.dat_dir()+\"Y_train.dat\")\n",
    "    \n",
    "    return X_test, X_train, Y_test, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many machine learning methods require that all variables in 'X' and 'Y' share a scaling, i.e. magnitudes must be normalized if they are in the same space as colors, because of the distance measures used in parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler():\n",
    "\n",
    "    X_test, X_train, Y_test, Y_train = data_vectors()\n",
    "    train_X = RS.fit_transform(X_train)\n",
    "    train_Y = Y_train\n",
    "    test_X  = RS.transform(X_test)\n",
    "    test_Y  = Y_test   \n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will plot the redshift, magnitude, and error distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution():\n",
    "\n",
    "    magerrs , mags, masterX, masterY  = data_vectors()\n",
    "\n",
    "    fig = plt.figure(1, figsize=(24,8))\n",
    "    gs = gridspec.GridSpec(1,3)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(masterY[:,0], kde=True, hist=False, label='Redshift')\n",
    "    #ax.set_xlim([0, 2.0])\n",
    "    ax.set_title('Redshift distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('Redshift', fontsize=18)    \n",
    "    ax = plt.subplot(gs[1])\n",
    "    sns.distplot(masterY[:,1], kde=True, hist=False, label=r'$M_{\\star}$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title('stellar mass distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('stellar mass', fontsize=18)    \n",
    "    ax = plt.subplot(gs[2])\n",
    "    sns.distplot(masterY[:,2], kde=True, hist=False, label=r'$SFR$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_title('size', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('R', fontsize=18)    \n",
    "    fig.savefig(util.fig_dir()+\"z.pdf\" , box_inches = \"tight\")\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(mags[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magnitude distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magnitudes', fontsize=18)    \n",
    "    fig.savefig(util.fig_dir()+\"mags.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(magerrs[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magerrs', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magerrs', fontsize=18)    \n",
    "    fig.savefig(util.fig_dir()+\"magerrs.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "    return None\n",
    "\n",
    "plot_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a top hat function parametrization of $z,\\alpha$ space for the probability distributions.  At this point we hardcode that $\\alpha$ is a scalar that we'll refer to as $M$ in this notebook because our first stab was with $\\alpha=M_{*}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bins(Y_train,num_bins):\n",
    "    \n",
    "    (nbins_z,nbins_M) = num_bins\n",
    "    \n",
    "    zmin, zmax = min(Y_train[:,0]), max(Y_train[:,0])\n",
    "    Mmin, Mmax = min(Y_train[:,1]), max(Y_train[:,1])\n",
    "   \n",
    "    zgrid = np.linspace(zmin, zmax, nbins_z+1)\n",
    "    Mgrid = np.linspace(Mmin, Mmax, nbins_M+1)\n",
    "    \n",
    "    X_train, Y_train, test_X, test_Y = scaler()\n",
    "    \n",
    "    (nbins_z,nbins_M) = num_bins\n",
    "    (bins_z,bins_M) = zgrid,Mgrid#make_bins(Y_train,num_bins)\n",
    "    zmin,zmax = min(bins_z),max(bins_z)\n",
    "    Mmin,Mmax = min(bins_M),max(bins_M)\n",
    "    binsize_z = (zmax - zmin)/ nbins_z\n",
    "    binsize_M = (Mmax - Mmin)/ nbins_M\n",
    "\n",
    "    L = np.zeros((len(Y_train)))\n",
    "    label_list = [] \n",
    "    \"\"\" Labeling the bins \"\"\"\n",
    "    for i in range(nbins_z):\n",
    "        for j in range(nbins_M):\n",
    "            ij = np.where((Y_train[:,0]>=zmin+i*binsize_z)&(Y_train[:,0]<zmin+(i+1)*binsize_z)&(Y_train[:,1]>=Mmin+j*binsize_M)&(Y_train[:,1]<Mmin+(j+1)*binsize_M))[0]\n",
    "            if (len(ij) != 0 ):\n",
    "                label_list.append([i,j])\n",
    "            L[ij] = i + j * nbins_M\n",
    "    \n",
    "    return ((zmin , binsize_z, Mmin, binsize_M),(L,label_list))#(zgrid,Mgrid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the class that implements two machine learning methods but could easily be extended to any others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifier(object):\n",
    "    def __init__(self,name,num_bins,**kwargs):\n",
    "        \n",
    "        \"\"\" Setting up the KNN classifier\"\"\"\n",
    "        ((self.zmin , self.binsize_z, self.Mmin, self.binsize_M),(self.L,self.label_list)) = make_bins(Y_train,num_bins)\n",
    "        \n",
    "        if name == 'knn':\n",
    "            \"\"\"\n",
    "            k nearest neighbors classifier for determining p(z)'s.\n",
    "            inputs:\n",
    "            num_bins = number of redshift bins,\n",
    "            num_neighbors = number of neighbors,\n",
    "            outputs:\n",
    "            label probabilities + best predictions + feature importance\n",
    "            \"\"\"\n",
    "            self.num_neighbors = kwargs['num_neighbors']\n",
    "            self.clf = KNeighborsClassifier(n_neighbors=self.num_neighbors)\n",
    "        if name == 'rf':\n",
    "            \"\"\"\n",
    "            random forest classifier for determining p(z)'s.\n",
    "            inputs:\n",
    "            num_bins = number of redshift bins,\n",
    "            num_estimators = number of estimators,\n",
    "            outputs:\n",
    "            label probabilities + best predictions + feature importance\n",
    "            \"\"\"\n",
    "            self.num_estimators = kwargs['num_estimators']\n",
    "            self.clf = RandomForestClassifier(n_estimators=self.num_estimators, \n",
    "                                              max_depth=None, min_samples_split=1, random_state=0)\n",
    "        return\n",
    "            \n",
    "    def run(self):\n",
    "        self.clf.n_classes_ = len(self.label_list)\n",
    "        \"\"\" training \"\"\"\n",
    "        self.clf.fit(X_train, self.L)\n",
    "        \"\"\"best predictions\"\"\"\n",
    "        Y_pred = self.clf.predict(test_X)\n",
    "        \"\"\"label probabilities\"\"\"\n",
    "        prob = self.clf.predict_proba(test_X) \n",
    "        \"\"\"transformation quantities \"\"\"\n",
    "        trans = self.zmin , self.binsize_z, self.Mmin, self.binsize_M\n",
    "        return self.L, self.label_list, prob , Y_pred, trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the classifiers as pseudo-regressors.  Random forests is highly memory intensive and sensitive to the number of classes.  $k$ nearest neighbors is faster and much more forgiving with the granularity of the space, but it is sensitive to the sparsity of the cells in training set space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "  \n",
    "RS = RobustScaler()\n",
    "    \n",
    "X_train, Y_train, test_X, test_Y = scaler()\n",
    "\n",
    "nbins_knn = (10,25)\n",
    "nbins_rf = (10,10)\n",
    "nn = 100\n",
    "ne = 100\n",
    "    \n",
    "clf_knn = classifier('knn', nbins_knn, num_neighbors = nn)\n",
    "clf_rf = classifier('rf', nbins_rf, num_estimators = ne)\n",
    "\n",
    "L_knn, label_list_knn, prob_knn, bestfit_knn, trans_knn = clf_knn.run() \n",
    "L_rf, label_list_rf, prob_rf, bestfit_rf, trans_rf = clf_rf.run()\n",
    "\n",
    "zmin_knn, binsize_z_knn, Mmin_knn, binsize_M_knn = trans_knn\n",
    "zmin_rf, binsize_z_rf, Mmin_rf, binsize_M_rf = trans_rf\n",
    "\n",
    "zrange_knn = zmin_knn + binsize_z_knn * np.arange(nbins_knn[0])\n",
    "mrange_knn = Mmin_knn + binsize_M_knn * np.arange(nbins_knn[1])\n",
    "zrange_rf = zmin_rf + binsize_z_rf * np.arange(nbins_rf[0])\n",
    "mrange_rf = Mmin_rf + binsize_M_rf * np.arange(nbins_rf[1])\n",
    "\n",
    "#print(zrange.shape, mrange.shape, prob.shape, bestfit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every galaxy in the catalog, we plot the posteriors $p(z,\\alpha)$ and the marginal posteriors $p(z)$ and $p(\\alpha)$ with the true values.  Some will show nontrivial covariance, which is the motivation for why $p(z,\\alpha)$ is an informative data product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_results(name,nbins,zrange,mrange,L,label_list,prob):\n",
    "    print(np.shape(L))\n",
    "    print(np.shape(label_list))\n",
    "    print(np.shape(prob))\n",
    "    for i in range(prob[:10].shape[0]):\n",
    "    \n",
    "       prob2d = np.zeros(nbins)\n",
    "    \n",
    "       for k in xrange(len(prob[i])):\n",
    "           \n",
    "           prob2d[label_list[k][0] , label_list[k][1]] = prob[i][k]\n",
    "\n",
    "       image = prob2d#[0][i,:][:,None] * prob[1][i,:][None,:] \n",
    "       image = image / np.sum(image)     \n",
    "       #plt.title(str())\n",
    "       plt.imshow(image , interpolation = \"none\", cmap = plt.cm.viridis, origin='lower')#,norm=LogNorm(vmin=-0.0000001, vmax=1))\n",
    "       ytick_locs = range(nbins[0])\n",
    "       ytick_lbls = np.round(zrange,2)\n",
    "       plt.yticks(ytick_locs, ytick_lbls)\n",
    "       plt.ylabel(r'$z$')\n",
    "       xtick_locs = range(nbins[1])\n",
    "       xtick_lbls = np.round(mrange,2)\n",
    "       plt.xticks(xtick_locs, xtick_lbls, rotation='vertical')\n",
    "       plt.xlabel(r'$M_{*}$')\n",
    "       plt.colorbar()\n",
    "       plt.savefig(util.fig_dir()+name+str(i)+\".png\")\n",
    "       plt.close()\n",
    "    \n",
    "       plt.plot(mrange, np.array(np.sum(prob2d,axis=0)), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,1], color='k', linestyle='--') \n",
    "       plt.xlabel(r'$M_{*}$')\n",
    "       plt.savefig(util.fig_dir()+name+str(i)+\"m.png\")\n",
    "       plt.close()\n",
    "       plt.plot(zrange, np.array(np.sum(prob2d,axis=1)), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,0], color='k', linestyle='--') \n",
    "       plt.xlabel(r'$z$')\n",
    "       plt.savefig(util.fig_dir()+name+str(i)+\"z.png\")\n",
    "       plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37009,)\n",
      "(117, 2)\n",
      "(44886, 117)\n",
      "(37009,)\n",
      "(56, 2)\n",
      "(44886, 56)\n"
     ]
    }
   ],
   "source": [
    "plot_results('knn',nbins_knn,zrange_knn,mrange_knn,L_knn,label_list_knn,prob_knn)\n",
    "plot_results('rf',nbins_rf,zrange_rf,mrange_rf,L_rf,label_list_rf,prob_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
