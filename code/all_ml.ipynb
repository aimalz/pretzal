{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import george\n",
    "import data\n",
    "import util \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "#from scipy.stats import beta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "from matplotlib import gridspec\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_vectors():\n",
    "\n",
    "    X_test = np.loadtxt(util.dat_dir()+\"X_test.dat\")\n",
    "    X_train = np.loadtxt(util.dat_dir()+\"X_train.dat\")\n",
    "   \n",
    "    Xerr_test = np.loadtxt(util.dat_dir()+\"Xerr_test.dat\")\n",
    "    Xerr_train = np.loadtxt(util.dat_dir()+\"Xerr_train.dat\")\n",
    "    \n",
    "    Y_test = np.loadtxt(util.dat_dir()+\"Y_test.dat\")\n",
    "    Y_train = np.loadtxt(util.dat_dir()+\"Y_train.dat\")\n",
    "    \n",
    "    return X_test, X_train, Y_test, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scaler():\n",
    "\n",
    "    X_test, X_train, Y_test, Y_train = data_vectors()\n",
    "    train_X = RS.fit_transform(X_train)\n",
    "    train_Y = Y_train\n",
    "    test_X  = RS.transform(X_test)\n",
    "    test_Y  = Y_test   \n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_distribution():\n",
    "\n",
    "    magerrs , mags, masterX, masterY  = data_vectors()\n",
    "\n",
    "    fig = plt.figure(1, figsize=(24,8))\n",
    "    gs = gridspec.GridSpec(1,3)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(masterY[:,0], kde=True, hist=False, label='Redshift')\n",
    "    #ax.set_xlim([0, 2.0])\n",
    "    ax.set_title('Redshift distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('Redshift', fontsize=18)    \n",
    "    ax = plt.subplot(gs[1])\n",
    "    sns.distplot(masterY[:,1], kde=True, hist=False, label=r'$M_{\\star}$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title('stellar mass distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('stellar mass', fontsize=18)    \n",
    "    ax = plt.subplot(gs[2])\n",
    "    sns.distplot(masterY[:,2], kde=True, hist=False, label=r'$SFR$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_title('size', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('R', fontsize=18)    \n",
    "    fig.savefig(util.fig_dir()+\"z.pdf\" , box_inches = \"tight\")\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(mags[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magnitude distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magnitudes', fontsize=18)    \n",
    "    fig.savefig(util.fig_dir()+\"mags.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(magerrs[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magerrs', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magerrs', fontsize=18)    \n",
    "    fig.savefig(util.fig_dir()+\"magerrs.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aimalz/anaconda/lib/python2.7/site-packages/matplotlib/axes/_axes.py:519: UserWarning: No labelled objects found. Use label='...' kwarg on individual plots.\n",
      "  warnings.warn(\"No labelled objects found. \"\n"
     ]
    }
   ],
   "source": [
    "plot_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_bins(Y_train,num_bins):\n",
    "    \n",
    "    (nbins_z,nbins_M) = num_bins\n",
    "    \n",
    "    zmin, zmax = min(Y_train[:,0]), max(Y_train[:,0])\n",
    "    Mmin, Mmax = min(Y_train[:,1]), max(Y_train[:,1])\n",
    "   \n",
    "    zgrid = np.linspace(zmin, zmax, nbins_z+1)\n",
    "    Mgrid = np.linspace(Mmin, Mmax, nbins_M+1)\n",
    "\n",
    "    binsize1 = (zmax - zmin)/ nbins_z\n",
    "    binsize2 = (Mmax - Mmin)/ nbins_M\n",
    "    \n",
    "    X_train, Y_train, test_X, test_Y = scaler()\n",
    "    \n",
    "    (nbins_z,nbins_M) = num_bins\n",
    "    (bins_z,bins_M) = zgrid,Mgrid#make_bins(Y_train,num_bins)\n",
    "    zmin,zmax = min(bins_z),max(bins_z)\n",
    "    Mmin,Mmax = min(bins_M),max(bins_M)\n",
    "    binsize_z = (zmax - zmin)/ nbins_z\n",
    "    binsize_M = (Mmax - Mmin)/ nbins_M\n",
    "\n",
    "    L = np.zeros((len(Y_train)))\n",
    "    label_list = [] \n",
    "    \"\"\" Labeling the bins \"\"\"\n",
    "    for i in range(nbins_z):\n",
    "        for j in range(nbins_M):\n",
    "            ij = np.where((Y_train[:,0]>=zmin+i*binsize_z)&(Y_train[:,0]<zmin+(i+1)*binsize_z)&(Y_train[:,1]>=Mmin+j*binsize_M)&(Y_train[:,1]<Mmin+(j+1)*binsize_M))[0]\n",
    "            if (len(ij) != 0 ):\n",
    "                label_list.append([i,j])\n",
    "            L[ij] = i + j * nbins_M\n",
    "    \n",
    "    return ((zmin , binsize_z, Mmin, binsize_M),(L,label_list))#(zgrid,Mgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifier(object):\n",
    "    def __init__(self,name,num_bins,**kwargs):\n",
    "        \n",
    "        \"\"\" Setting up the KNN classifier\"\"\"\n",
    "        ((self.zmin , self.binsize_z, self.Mmin, self.binsize_M),(self.L,self.label_list)) = make_bins(Y_train,num_bins)\n",
    "        \n",
    "        if name == 'knn':\n",
    "            \"\"\"\n",
    "            k nearest neighbors classifier for determining p(z)'s.\n",
    "            inputs:\n",
    "            num_bins = number of redshift bins,\n",
    "            num_neighbors = number of neighbors,\n",
    "            outputs:\n",
    "            label probabilities + best predictions + feature importance\n",
    "            \"\"\"\n",
    "            self.num_neighbors = kwargs['num_neighbors']\n",
    "            self.clf = KNeighborsClassifier(n_neighbors=self.num_neighbors)\n",
    "        if name == 'rf':\n",
    "            \"\"\"\n",
    "            random forest classifier for determining p(z)'s.\n",
    "            inputs:\n",
    "            num_bins = number of redshift bins,\n",
    "            num_estimators = number of estimators,\n",
    "            outputs:\n",
    "            label probabilities + best predictions + feature importance\n",
    "            \"\"\"\n",
    "            self.num_estimators = kwargs['num_estimators']\n",
    "            self.clf = RandomForestClassifier(n_estimators=self.num_estimators, \n",
    "                                              max_depth=None, min_samples_split=1, random_state=0)\n",
    "        return\n",
    "            \n",
    "    def run(self):\n",
    "        self.clf.n_classes_ = len(self.label_list)\n",
    "        \"\"\" training \"\"\"\n",
    "        self.clf.fit(X_train, self.L)\n",
    "        \"\"\"best predictions\"\"\"\n",
    "        Y_pred = self.clf.predict(test_X)\n",
    "        \"\"\"label probabilities\"\"\"\n",
    "        prob = self.clf.predict_proba(test_X) \n",
    "        \"\"\"transformation quantities \"\"\"\n",
    "        trans = self.zmin , self.binsize_z, self.Mmin, self.binsize_M\n",
    "        return self.L, self.label_list, prob , Y_pred, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.colors import LogNorm\n",
    "  \n",
    "RS = RobustScaler()\n",
    "    \n",
    "X_train, Y_train, test_X, test_Y = scaler()\n",
    "\n",
    "nbins_knn = (10,25)\n",
    "nbins_rf = (10,10)\n",
    "nn = 100\n",
    "ne = 100\n",
    "\n",
    "    \n",
    "clf_knn = classifier('knn', nbins_knn, num_neighbors = nn)\n",
    "clf_rf = classifier('rf', nbins_rf, num_estimators = ne)\n",
    "\n",
    "L_knn, label_list_knn, prob_knn, bestfit_knn, trans_knn = clf_knn.run() \n",
    "L_rf, label_list_rf, prob_rf, bestfit_rf, trans_rf = clf_rf.run()\n",
    "\n",
    "zmin_knn, binsize_z_knn, Mmin_knn, binsize_M_knn = trans_knn\n",
    "zmin_rf, binsize_z_rf, Mmin_rf, binsize_M_rf = trans_rf\n",
    "\n",
    "zrange_knn = zmin_knn + binsize_z_knn * np.arange(nbins_knn[0])\n",
    "mrange_knn = Mmin_knn + binsize_M_knn * np.arange(nbins_knn[1])\n",
    "zrange_rf = zmin_rf + binsize_z_rf * np.arange(nbins_rf[0])\n",
    "mrange_rf = Mmin_rf + binsize_M_rf * np.arange(nbins_rf[1])\n",
    "\n",
    "#print(zrange.shape, mrange.shape, prob.shape, bestfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_results(name,nbins,zrange,mrange,L,label_list,prob):\n",
    "    print(np.shape(L))\n",
    "    print(np.shape(label_list))\n",
    "    print(np.shape(prob))\n",
    "    for i in range(prob[:10].shape[0]):\n",
    "    \n",
    "       prob2d = np.zeros(nbins)\n",
    "    \n",
    "       for k in xrange(len(prob[i])):\n",
    "           \n",
    "           prob2d[label_list[k][0] , label_list[k][1]] = prob[i][k]\n",
    "\n",
    "       image = prob2d#[0][i,:][:,None] * prob[1][i,:][None,:] \n",
    "       image = image / np.sum(image)     \n",
    "       #plt.title(str())\n",
    "       plt.imshow(image , interpolation = \"none\", cmap = plt.cm.viridis, origin='lower')#,norm=LogNorm(vmin=-0.0000001, vmax=1))\n",
    "       ytick_locs = range(nbins[0])\n",
    "       ytick_lbls = np.round(zrange,2)\n",
    "       plt.yticks(ytick_locs, ytick_lbls)\n",
    "       plt.ylabel(r'$z$')\n",
    "       xtick_locs = range(nbins[1])\n",
    "       xtick_lbls = np.round(mrange,2)\n",
    "       plt.xticks(xtick_locs, xtick_lbls, rotation='vertical')\n",
    "       plt.xlabel(r'$M_{*}$')\n",
    "       plt.colorbar()\n",
    "       plt.savefig(util.fig_dir()+name+str(i)+\".png\")\n",
    "       plt.close()\n",
    "    \n",
    "       plt.plot(mrange, np.array(np.sum(prob2d,axis=0)), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,1], color='k', linestyle='--') \n",
    "       plt.xlabel(r'$M_{*}$')\n",
    "       plt.savefig(util.fig_dir()+name+str(i)+\"m.png\")\n",
    "       plt.close()\n",
    "       plt.plot(zrange, np.array(np.sum(prob2d,axis=1)), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,0], color='k', linestyle='--') \n",
    "       plt.xlabel(r'$z$')\n",
    "       plt.savefig(util.fig_dir()+name+str(i)+\"z.png\")\n",
    "       plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_results('knn',nbins_knn,zrange_knn,mrange_knn,L_knn,label_list_knn,prob_knn)\n",
    "plot_results('rf',nbins_rf,zrange_rf,mrange_rf,L_rf,label_list_rf,prob_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import george\n",
    "import data\n",
    "import util \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.stats import beta\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "from matplotlib import gridspec\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RS = RobustScaler()\n",
    "\n",
    "def data_vectors():\n",
    "\n",
    "    X_test = np.loadtxt(util.dat_dir()+\"X_test.dat\")\n",
    "    X_train = np.loadtxt(util.dat_dir()+\"X_train.dat\")\n",
    "   \n",
    "    Xerr_test = np.loadtxt(util.dat_dir()+\"Xerr_test.dat\")\n",
    "    Xerr_train = np.loadtxt(util.dat_dir()+\"Xerr_train.dat\")\n",
    "    \n",
    "    Y_test = np.loadtxt(util.dat_dir()+\"Y_test.dat\")\n",
    "    Y_train = np.loadtxt(util.dat_dir()+\"Y_train.dat\")\n",
    "    \n",
    "    return X_test, X_train, Y_test, Y_train\n",
    "\n",
    "\n",
    "def scaler():\n",
    "\n",
    "    X_test, X_train, Y_test, Y_train = data_vectors()\n",
    "    train_X = RS.fit_transform(X_train)\n",
    "    train_Y = Y_train\n",
    "    test_X  = RS.transform(X_test)\n",
    "    test_Y  = Y_test   \n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y    \n",
    "\n",
    "\n",
    "def rf(num_bins, num_estimators):\n",
    "    \n",
    "    \"\"\"\n",
    "    random forest classifier for determining p(z)'s.\n",
    "    inputs:\n",
    "    num_bins = number of redshift bins,\n",
    "    num_estimators = number of estimators in scikit-learn random forrest classifier,\n",
    "    outputs:\n",
    "    label probabilities + best predictions + feature importance\n",
    "    \"\"\"\n",
    "    \"\"\" Binning the redshifts\"\"\"\n",
    "   \n",
    "    X_train, Y_train, test_X, test_Y = scaler()\n",
    "   \n",
    "    nbins = num_bins\n",
    "    zmin, zmax = min(Y_train[:,0]), max(Y_train[:,0])\n",
    "    Mmin, Mmax = min(Y_train[:,1]), max(Y_train[:,1])\n",
    "   \n",
    "    #print Mmin , Mmax, zmin, zmax\n",
    " \n",
    "    zgrid = np.linspace(zmin, zmax, nbins)\n",
    "    Mgrid = np.linspace(Mmin, Mmax, nbins)\n",
    "\n",
    "    binsize1 = (zmax - zmin)/ nbins\n",
    "    binsize2 = (Mmax - Mmin)/ nbins\n",
    "    \n",
    "    #L = np.zeros((len(Y_train)))\n",
    "    L = np.zeros((len(Y_train), 2))\n",
    "    \n",
    "    \n",
    "    \"\"\" Labeling the bins \"\"\"\n",
    "    for i in range(nbins):\n",
    "        for j in range(nbins):\n",
    "            ij = np.where((Y_train[:,0]>=zmin+i*binsize1)&(Y_train[:,0]<zmin+(i+1)*binsize1)&(Y_train[:,1]>=Mmin+j*binsize2)&(Y_train[:,1]<Mmin+(j+1)*binsize2))\n",
    "            #print ij, \"ball\"\n",
    "            L[ij] = [i,j]\n",
    "     \n",
    "    \"\"\" Splitting the data into training and test sets\"\"\"\n",
    "    \n",
    "    #L = L.astype(int)\n",
    "    \n",
    "    \"\"\" Setting up the RF classifier\"\"\"\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=num_estimators, max_depth=None, min_samples_split=1, random_state=0)\n",
    "    clf.n_classes_ = [nbins , nbins]\n",
    "    #clf.classes_ = np.arange(nbins * nbins)    \n",
    "    \"\"\" training \"\"\"\n",
    "    clf.fit(X_train, L)\n",
    "    \"\"\"feature importance \"\"\"\n",
    "    fi = clf.feature_importances_\n",
    "    \n",
    "    \"\"\"best predictions\"\"\"\n",
    "    Y_pred = clf.predict(test_X)\n",
    "    \"\"\"label probabilities\"\"\"\n",
    "    prob = clf.predict_proba(test_X) \n",
    "    \"\"\"transformation quantities \"\"\"\n",
    "    trans = zmin , binsize1, Mmin, binsize2\n",
    "\n",
    "    return prob , Y_pred, trans\n",
    "\n",
    "\n",
    "def plot_distribution():\n",
    "\n",
    "    magerrs , mags, masterX, masterY  = data_vectors()\n",
    "\n",
    "    fig = plt.figure(1, figsize=(24,8))\n",
    "    gs = gridspec.GridSpec(1,3)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(masterY[:,0], kde=True, hist=False, label='Redshift')\n",
    "    #ax.set_xlim([0, 2.0])\n",
    "    ax.set_title('Redshift distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('Redshift', fontsize=18)    \n",
    "    ax = plt.subplot(gs[1])\n",
    "    sns.distplot(masterY[:,1], kde=True, hist=False, label=r'$M_{\\star}$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_title('stellar mass distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('stellar mass', fontsize=18)    \n",
    "    ax = plt.subplot(gs[2])\n",
    "    sns.distplot(masterY[:,2], kde=True, hist=False, label=r'$SFR$')\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_title('size', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('R', fontsize=18)    \n",
    "    fig.savefig(\"z.pdf\" , box_inches = \"tight\")\n",
    "    \n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(mags[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(mags[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magnitude distrubtion', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magnitudes', fontsize=18)    \n",
    "    fig.savefig(\"mags.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "\n",
    "    fig = plt.figure(1, figsize=(8,8))\n",
    "    gs = gridspec.GridSpec(1,1)\n",
    "    ax = plt.subplot(gs[0])\n",
    "    sns.distplot(magerrs[:,0], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,1], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,2], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,3], kde=True, hist=False, label = '')\n",
    "    sns.distplot(magerrs[:,4], kde=True, hist=False, label = '')\n",
    "    ax.set_title('magerrs', fontsize=18)\n",
    "    ax.legend(fontsize=13)\n",
    "    ax.set_xlabel('magerrs', fontsize=18)    \n",
    "    fig.savefig(\"magerrs.pdf\" , box_inches = \"tight\")\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    from matplotlib.colors import LogNorm\n",
    "    \n",
    "    X_train, Y_train, test_X, test_Y = scaler()\n",
    "    \n",
    "    prob , bestfit , trans = rf(num_bins = 20, num_estimators=500) \n",
    "    zmin , binsize1, Mmin, binsize2 = trans\n",
    "\n",
    "    print prob[0].shape\n",
    "    print prob[1].shape\n",
    "\n",
    "    zrange = zmin + binsize1 * np.arange(10)\n",
    "    mrange = Mmin + binsize2 * np.arange(10)\n",
    "\n",
    "    for i in range(prob[1].shape[0]):\n",
    "\n",
    "       \n",
    "       image = prob[0][i,:][:,None] * prob[1][i,:][None,:] \n",
    "       image = image / np.sum(image)     \n",
    "       plt.imshow(image , interpolation = \"none\", cmap = plt.cm.viridis)#,norm=LogNorm(vmin=-0.0000001, vmax=1))\n",
    "       plt.colorbar()\n",
    "       plt.savefig(util.fig_dir()+str(i)+\".png\")\n",
    "       plt.close()\n",
    "\n",
    "       plt.plot(mrange, np.array(prob[1][i,:]), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,1], color='k', linestyle='--') \n",
    "       plt.savefig(util.fig_dir()+str(i)+\"m.png\")\n",
    "       plt.close()\n",
    "       plt.plot(zrange, np.array(prob[0][i,:]), color='blue' , drawstyle='steps-mid')\n",
    "       plt.axvline(x=test_Y[i,0], color='k', linestyle='--') \n",
    "       plt.savefig(util.fig_dir()+str(i)+\"z.png\")\n",
    "       plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(num_bins, n_neighbors):\n",
    "    \n",
    "    \"\"\"\n",
    "    k nearest neighbors classifier for determining p(z)'s.\n",
    "    inputs:\n",
    "    num_bins = number of redshift bins,\n",
    "    num_estimators = number of neighbors,\n",
    "    outputs:\n",
    "    label probabilities + best predictions + feature importance\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\" Setting up the KNN classifier\"\"\"\n",
    "\n",
    "    ((zmin , binsize_z, Mmin, binsize_M),(L,label_list)) = make_bins(Y_train,num_bins)\n",
    "    # clf = RandomForestClassifier(n_estimators=num_estimators, max_depth=None, min_samples_split=1, random_state=0)\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.n_classes_ = len(label_list)#[nbins , nbins]\n",
    "    #clf.classes_ = np.arange(nbins * nbins)    \n",
    "    \"\"\" training \"\"\"\n",
    "    clf.fit(X_train, L)\n",
    "    \"\"\"feature importance \"\"\"\n",
    "    # fi = clf.feature_importances_\n",
    "    \n",
    "    \"\"\"best predictions\"\"\"\n",
    "    Y_pred = clf.predict(test_X)\n",
    "    \"\"\"label probabilities\"\"\"\n",
    "    prob = clf.predict_proba(test_X) \n",
    "    \"\"\"transformation quantities \"\"\"\n",
    "    trans = zmin , binsize_z, Mmin, binsize_M\n",
    "\n",
    "    return prob , Y_pred, trans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
